{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4aa2322-889a-466b-ae4d-8a50f60ed2f0",
   "metadata": {},
   "source": [
    "# Cell 1: Imports & configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "883d22bc-3c9d-4301-b995-51889c33d62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ USER CONFIG ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# CSV of domains (download separately or via script)\n",
    "CSV_FILE        = \"majestic_million.csv\"\n",
    "# Where to persist crawl progress\n",
    "STATE_FILES     = {\"tos\": \"state_tos.json\", \"pp\": \"state_pp.json\"}\n",
    "# API endpoints (set in .env or here)\n",
    "TOS_ENDPOINT    = \"http://localhost:8080/api/v1/crawl-tos\"\n",
    "PP_ENDPOINT     = \"http://localhost:8080/api/v1/crawl-pp\"\n",
    "API_KEY         = os.getenv(\"X_API_KEY\")\n",
    "# how many successful crawls per stage\n",
    "TARGET_SUCCESSES = 100\n",
    "# network/time settings\n",
    "TIMEOUT         = 10     # seconds\n",
    "DELAY           = 0.1    # seconds between requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f483ea-1766-4441-a673-ecf2f95e4c3d",
   "metadata": {},
   "source": [
    "# Cell 2: Download Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83763e0c-d85a-4bb2-8077-b72c148cd932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV already exists; skipping download.\n",
      "Loaded 1,000,000 domains.  First few:\n",
      "    GlobalRank         Domain\n",
      "0           1     google.com\n",
      "1           2   facebook.com\n",
      "2           3    youtube.com\n",
      "3           4    twitter.com\n",
      "4           5  instagram.com\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(CSV_FILE):\n",
    "    print(\"Downloading Majestic Million list‚Ä¶\")\n",
    "    resp = requests.get(CSV_URL, stream=True, timeout=TIMEOUT)\n",
    "    resp.raise_for_status()\n",
    "    with open(CSV_FILE, \"wb\") as f:\n",
    "        for chunk in resp.iter_content(chunk_size=1024):\n",
    "            f.write(chunk)\n",
    "else:\n",
    "    print(\"CSV already exists; skipping download.\")\n",
    "\n",
    "# Now read the real header row and pull exactly GlobalRank + Domain\n",
    "df = pd.read_csv(\n",
    "    CSV_FILE,\n",
    "    usecols=[\"GlobalRank\", \"Domain\"],\n",
    "    dtype={\"GlobalRank\": int, \"Domain\": str},\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "# Make sure it‚Äôs sorted\n",
    "df = df.sort_values(\"GlobalRank\").reset_index(drop=True)\n",
    "\n",
    "print(f\"Loaded {len(df):,} domains.  First few:\\n\", df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e9fceb-f566-4c2b-8d01-6861b4fc5ecf",
   "metadata": {},
   "source": [
    "# Cell 3: Health check your service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ce47fc4-eb0a-4fe0-90ff-31555b23bab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking service at http://localhost:8080/api/test ‚Ä¶\n",
      "‚úÖ Service is up: Server is running\n"
     ]
    }
   ],
   "source": [
    "health_url = \"http://localhost:8080/api/test\"\n",
    "print(\"Checking service at\", health_url, \"‚Ä¶\")\n",
    "\n",
    "try:\n",
    "    r = requests.get(health_url, timeout=TIMEOUT)\n",
    "    r.raise_for_status()\n",
    "    js = r.json()\n",
    "    assert js.get(\"status\") == \"ok\"\n",
    "    print(\"‚úÖ Service is up:\", js.get(\"message\", \"<no message>\"))\n",
    "except Exception as e:\n",
    "    raise SystemExit(f\"‚ùå Health check failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99ad4ac-5fe3-432a-b93d-1a88b3609607",
   "metadata": {},
   "source": [
    "# Cell 4: Define the crawl function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4934af4-f6fc-45e7-916d-e6ddda717805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_stage(df, stage_name, endpoint):\n",
    "    \"\"\"Crawl until TARGET_SUCCESSES successes for given stage.\"\"\"\n",
    "    state_file = STATE_FILES[stage_name]\n",
    "    # load or init\n",
    "    if os.path.exists(state_file):\n",
    "        state = json.load(open(state_file))\n",
    "    else:\n",
    "        state = {\"last_rank\": 0, \"success\": 0, \"fail\": 0}\n",
    "\n",
    "    last_rank = state[\"last_rank\"]\n",
    "    succ      = state[\"success\"]\n",
    "    fail      = state[\"fail\"]\n",
    "\n",
    "    # display header\n",
    "    clear_output(wait=True)\n",
    "    print(f\"[{stage_name.upper()}] Resuming at rank {last_rank}: \"\n",
    "          f\"{succ}‚úÖ, {fail}‚ùå\")\n",
    "\n",
    "    # filter remaining domains\n",
    "    to_crawl = df[df.GlobalRank > last_rank].sort_values(\"GlobalRank\")\n",
    "    pbar     = tqdm(to_crawl.itertuples(index=False), total=len(to_crawl),\n",
    "                    desc=f\"crawl-{stage_name}\")\n",
    "    \n",
    "    for row in pbar:\n",
    "        if succ >= TARGET_SUCCESSES:\n",
    "            break\n",
    "\n",
    "        rank, domain = row.GlobalRank, row.Domain\n",
    "        ok = False\n",
    "        try:\n",
    "            resp = requests.post(\n",
    "                endpoint,\n",
    "                json={\"url\": domain},\n",
    "                headers={\"X-API-KEY\": API_KEY},\n",
    "            )\n",
    "            resp.raise_for_status()\n",
    "            ok = resp.json().get(\"success\", False)\n",
    "        except Exception:\n",
    "            ok = False\n",
    "\n",
    "        # update counts and state\n",
    "        if ok:\n",
    "            succ += 1\n",
    "        else:\n",
    "            fail += 1\n",
    "        state = {\"last_rank\": rank, \"success\": succ, \"fail\": fail}\n",
    "        with open(state_file, \"w\") as f:\n",
    "            json.dump(state, f)\n",
    "\n",
    "        # live summary\n",
    "        clear_output(wait=True)\n",
    "        pct = succ / (succ + fail) * 100 if (succ + fail) else 0\n",
    "        print(f\"[{stage_name.upper()}] Rank {rank}: {succ}‚úÖ, {fail}‚ùå ({pct:.2f}%)\")\n",
    "\n",
    "        time.sleep(DELAY)\n",
    "\n",
    "    pbar.close()\n",
    "    print(f\"üéâ [{stage_name.upper()}] Done: {succ} successes, {fail} failures.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c9a0c0-b1ef-464e-9559-388872ba217b",
   "metadata": {},
   "source": [
    "# Cell 5: Run both stages back-to-back, but only start PP after tos reaches TARGET_SUCCESSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93f5189-d73c-4d13-b17e-ac56eeff5407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PP] Rank 240: 99‚úÖ, 141‚ùå (41.25%)\n"
     ]
    }
   ],
   "source": [
    "# ‚Äî run ToS stage\n",
    "crawl_stage(df, \"tos\", TOS_ENDPOINT)\n",
    "\n",
    "# ‚Äî check ToS state\n",
    "tos_state = json.load(open(STATE_FILES[\"tos\"]))\n",
    "if tos_state[\"success\"] >= TARGET_SUCCESSES:\n",
    "    crawl_stage(df, \"pp\", PP_ENDPOINT)\n",
    "else:\n",
    "    print(\n",
    "      f\"‚ÑπÔ∏è  Skipping Privacy Policy crawl: \"\n",
    "      f\"only {tos_state['success']} successes on ToS (target is {TARGET_SUCCESSES})\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9a8253-826d-4941-a84f-9df8ae585430",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
